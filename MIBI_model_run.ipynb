{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook is designed to facilitate the training and evaluation of a Vision Transformer (ViT) model for binary classification tasks using MIBI (Multiplexed Imaging) datasets.\n",
    " \n",
    "The main functions of this notebook include:\n",
    " \n",
    "1. **CUDA Availability Check**: The notebook checks if a CUDA-enabled GPU is available for training, which can significantly speed up the training process.\n",
    "\n",
    "2. **Data Loading**: It utilizes the `MibiDataset` class to load training, validation, and testing datasets from specified HDF5 files. Data loaders are created for each dataset to facilitate batch processing during training.\n",
    " \n",
    "3. **Model Training**: The notebook is set up to train a ViT model using the `train_model` function from the `model_utils` module. This function handles the training loop, loss calculation, and optimization.\n",
    "\n",
    "4. **Model Evaluation**: After training, the model can be evaluated on the validation and test datasets to assess its performance using various metrics.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Number of GPUs available: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "PyTorch built with CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"PyTorch built with CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "notebook_path=os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path,'NN_Framework')))\n",
    "from NN_Framework import model_utils\n",
    "from NN_Framework.mibi_dataset import MibiDataset\n",
    "from NN_Framework.models import ViTClassifier, DenseNet, SwinTransformer\n",
    "from NN_Framework.multichannel_transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_types = ['MelanA.tif', 'Ki67.tif', 'SOX10.tif', 'COL1A1.tif', 'SMA.tif', \n",
    "                            'CD206.tif', 'CD8.tif', 'CD4.tif', 'CD45.tif', 'CD3.tif', 'CD20.tif', 'CD11c.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NN_Framework.multichannel_transforms.Compose3D object at 0x000001F1F8E5A580>\n"
     ]
    }
   ],
   "source": [
    "train_transforms = Compose3D([\n",
    "    RandomHorizontalFlip3D(p=0.5),\n",
    "    RandomVerticalFlip3D(p=0.5),\n",
    "    RandomRotation3D(p=0.5),\n",
    "])\n",
    "print(train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r'D:\\MIBI-TOFF\\Data_For_Amos'\n",
    "train_dataset=MibiDataset(hdf5_path=r'D:\\MIBI-TOFF\\Scratch\\training_1024.h5',transform=train_transforms,expressions=expression_types)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=5,shuffle=True, num_workers=4,pin_memory=True)\n",
    "\n",
    "val_dataset=MibiDataset(hdf5_path=r'D:\\MIBI-TOFF\\Scratch\\validation_1024.h5',expressions=expression_types)\n",
    "val_loader=DataLoader(dataset=val_dataset,batch_size=5,shuffle=True, num_workers=4,pin_memory=True)\n",
    "\n",
    "test_dataset=MibiDataset(hdf5_path=r'D:\\MIBI-TOFF\\Scratch\\testing_1024.h5',expressions=expression_types)\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=5,shuffle=True, num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom collections import defaultdict\\n\\ndef plot_expression_histogram(loader, title, expressions, num_bins=50):\\n    class_0_counts = [defaultdict(int) for _ in range(len(expressions))]\\n    class_1_counts = [defaultdict(int) for _ in range(len(expressions))]\\n\\n    for patches, labels in loader:\\n        for i in range(len(expressions)):\\n            mask_0 = labels == 0\\n            mask_1 = labels == 1\\n            \\n            if mask_0.any():\\n                values_class_0 = patches[mask_0, i, :, :].flatten().numpy()\\n                for val in values_class_0:\\n                    if val != 0: \\n                        class_0_counts[i][val] += 1\\n            if mask_1.any():\\n                values_class_1 = patches[mask_1, i, :, :].flatten().numpy()\\n                for val in values_class_1:\\n                    if val != 0:  \\n                        class_1_counts[i][val] += 11\\n\\n    n_rows = (len(expressions) + 2) // 3\\n    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\\n    fig.suptitle(f\\'Expression Distributions - {title}\\', fontsize=16)\\n    fig.subplots_adjust(top=0.9)\\n    \\n    axes_flat = axes.flatten() if n_rows > 1 else axes\\n    \\n    for i, (exp_name, ax) in enumerate(zip(expressions, axes_flat)):\\n        exp_name = exp_name.replace(\\'.tif\\', \\'\\')\\n\\n        if class_0_counts[i]:\\n            values_0, counts_0 = zip(*sorted(class_0_counts[i].items()))\\n            hist_0, bin_edges = np.histogram(values_0, bins=num_bins, weights=counts_0)\\n            ax.bar(bin_edges[:-1], hist_0, width=np.diff(bin_edges), alpha=0.5, label=\\'Class 0\\')\\n\\n        if class_1_counts[i]:\\n            values_1, counts_1 = zip(*sorted(class_1_counts[i].items()))\\n            hist_1, bin_edges = np.histogram(values_1, bins=bin_edges, weights=counts_1)\\n            ax.bar(bin_edges[:-1], hist_1, width=np.diff(bin_edges), alpha=0.5, label=\\'Class 1\\')\\n        \\n        ax.set_title(exp_name)\\n        ax.legend()\\n        \\n    for i in range(len(expressions), len(axes_flat)):\\n        fig.delaxes(axes_flat[i])\\n        \\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\\n    plt.show()\\n\\nplot_expression_histogram(train_loader, \"Training Set\", expression_types)\\nplot_expression_histogram(val_loader, \"Validation Set\", expression_types)\\nplot_expression_histogram(test_loader, \"Test Set\", expression_types)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_expression_histogram(loader, title, expressions, num_bins=50):\n",
    "    class_0_counts = [defaultdict(int) for _ in range(len(expressions))]\n",
    "    class_1_counts = [defaultdict(int) for _ in range(len(expressions))]\n",
    "\n",
    "    for patches, labels in loader:\n",
    "        for i in range(len(expressions)):\n",
    "            mask_0 = labels == 0\n",
    "            mask_1 = labels == 1\n",
    "            \n",
    "            if mask_0.any():\n",
    "                values_class_0 = patches[mask_0, i, :, :].flatten().numpy()\n",
    "                for val in values_class_0:\n",
    "                    if val != 0: \n",
    "                        class_0_counts[i][val] += 1\n",
    "            if mask_1.any():\n",
    "                values_class_1 = patches[mask_1, i, :, :].flatten().numpy()\n",
    "                for val in values_class_1:\n",
    "                    if val != 0:  \n",
    "                        class_1_counts[i][val] += 11\n",
    "\n",
    "    n_rows = (len(expressions) + 2) // 3\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\n",
    "    fig.suptitle(f'Expression Distributions - {title}', fontsize=16)\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    \n",
    "    axes_flat = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    for i, (exp_name, ax) in enumerate(zip(expressions, axes_flat)):\n",
    "        exp_name = exp_name.replace('.tif', '')\n",
    "\n",
    "        if class_0_counts[i]:\n",
    "            values_0, counts_0 = zip(*sorted(class_0_counts[i].items()))\n",
    "            hist_0, bin_edges = np.histogram(values_0, bins=num_bins, weights=counts_0)\n",
    "            ax.bar(bin_edges[:-1], hist_0, width=np.diff(bin_edges), alpha=0.5, label='Class 0')\n",
    "\n",
    "        if class_1_counts[i]:\n",
    "            values_1, counts_1 = zip(*sorted(class_1_counts[i].items()))\n",
    "            hist_1, bin_edges = np.histogram(values_1, bins=bin_edges, weights=counts_1)\n",
    "            ax.bar(bin_edges[:-1], hist_1, width=np.diff(bin_edges), alpha=0.5, label='Class 1')\n",
    "        \n",
    "        ax.set_title(exp_name)\n",
    "        ax.legend()\n",
    "        \n",
    "    for i in range(len(expressions), len(axes_flat)):\n",
    "        fig.delaxes(axes_flat[i])\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "plot_expression_histogram(train_loader, \"Training Set\", expression_types)\n",
    "plot_expression_histogram(val_loader, \"Validation Set\", expression_types)\n",
    "plot_expression_histogram(test_loader, \"Test Set\", expression_types)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 228, 1: 245}\n",
      "{0: 44, 1: 24}\n",
      "{0: 20, 1: 42}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_counts)\n",
    "print(val_dataset.class_counts)\n",
    "print(test_dataset.class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swin\n",
      "True cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name='1024_swin_12_channel_'\n",
    "img_size=1024\n",
    "\n",
    "# Model selection based on name\n",
    "if any(x in model_name.lower() for x in ['swint', 'swin']):\n",
    "    print('Swin')\n",
    "    model = SwinTransformer(\n",
    "        img_size=1024, in_channels=12, patch_size=16, num_classes=2,\n",
    "        embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "        window_size=7, mlp_ratio=4.0, dropout_rate=0.1, weight_decay=0.05)\n",
    "    \n",
    "elif any(x in model_name.lower() for x in ['vit']):\n",
    "    dims_scaling = 2\n",
    "    model = ViTClassifier(\n",
    "        img_size_x=img_size, img_size_y=img_size, in_channels=12, num_classes=2,\n",
    "        patch_size_x=32, patch_size_y=32, embed_dim=768*dims_scaling, num_heads=12,\n",
    "        depth=12, mlp_dim=768*dims_scaling*4, dropout_rate=0.1, weight_decay=1e-5)\n",
    "    \n",
    "elif any(x in model_name.lower() for x in ['dn', 'densenet']):\n",
    "    model = DenseNet(\n",
    "        num_init_features=96, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "        num_classes=2, bn_size=4, dropout_rate=0.25, input_channels=12)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Model type not recognized in model name: {model_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define the classification criterion\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=1e-5)  # Define the optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Set device to GPU (0)\n",
    "model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(torch.cuda.is_available(),device)\n",
    "print(next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending MLFlow if an issue causes it to not close correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Block\n",
    "params_block={'location':r'D:\\MIBI-TOFF\\Scratch\\DL_Results',\n",
    "'epochs':200,\n",
    "'patience':200,\n",
    "'delta':0.00000001,\n",
    "'check_val_freq':5,\n",
    "'num_classes':2,\n",
    "'model_name':model_name,\n",
    "'log_with_mlflow':True,\n",
    "'mlflow_uri':\"http://127.0.0.1:5000\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started MLflow run with ID: 95be5f23e5c648359a7c436de314ea39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_utils.train_model(model, train_loader, val_loader, criterion, optimizer, device, location=params_block['location'], \n",
    "    epochs=params_block['epochs'], patience=params_block['patience'], delta=params_block['delta'], check_val_freq=params_block['check_val_freq'],\n",
    "    num_classes=params_block['num_classes'], model_name=params_block['model_name'], log_with_mlflow=params_block['log_with_mlflow'], mlflow_uri=params_block['mlflow_uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_37860\\3852113537.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(params_block['location'], f\"{params_block['model_name']}best_model.pth\")))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\MIBI-TOFF\\\\Scratch\\\\DL_Results\\\\1024_SwinT_12_channel_best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m avg_test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model_utils\u001b[38;5;241m.\u001b[39meval_model(model, test_loader, criterion, device, params_block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m], epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\MIBI-TOFF\\\\Scratch\\\\DL_Results\\\\1024_SwinT_12_channel_best_model.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(os.path.join(params_block['location'], f\"{params_block['model_name']}best_model.pth\")))\n",
    "\n",
    "avg_test_loss, test_metrics = model_utils.eval_model(model, test_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the eval_model function\n",
    "avg_val_loss, val_metrics = model_utils.eval_model(model, val_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "# Print all the metrics\n",
    "print(f\"Test Loss: {avg_val_loss:.4f}\")\n",
    "for metric_val_name, metric_val_value in val_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loader)\n",
    "print(val_loader)\n",
    "# Compare the contents of the two loaders\n",
    "test_data = [data for data, _ in test_loader]\n",
    "val_data = [data for data, _ in val_loader]\n",
    "\n",
    "# Check if the lengths of the datasets are the same\n",
    "if len(test_data) == len(val_data):\n",
    "    print(\"The test and validation loaders have the same number of batches.\")\n",
    "else:\n",
    "    print(f\"The test loader has {len(test_data)} batches, while the validation loader has {len(val_data)} batches.\")\n",
    "\n",
    "# Compare the contents of the first batch in both loaders\n",
    "if test_data and val_data:\n",
    "    print(\"Comparing the first batch of test and validation loaders:\")\n",
    "    print(\"Test batch:\", test_data[0])\n",
    "    print(\"Validation batch:\", val_data[0])\n",
    "else:\n",
    "    print(\"One of the loaders is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mibivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
