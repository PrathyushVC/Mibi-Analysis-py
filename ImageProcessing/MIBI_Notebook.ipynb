{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed installs\n",
    "#%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from mibi_dataset import MibiDataset\n",
    "from sklearn.model_selection import train_test_split,GroupShuffleSplit\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'cell_size', '128Te', '129Xe', '12C', '130Xe', '131Xe', '132Xe', '137Ba', '138Ba', '139La', '140Ce', '181Ta', '182Empty', '197Au', '23Na', '24Mg', '25Mg', '27Al', '28Si', '31P', '32Si', '39K', '40Ca', '41K', '56Fe', '64Zn', '66Zn', 'Alexa Fluor 488', 'Bax', 'CCR7', 'CD11c', 'CD14', 'CD163', 'CD20', 'CD206', 'CD21', 'CD3', 'CD31', 'CD4', 'CD45', 'CD45RA', 'CD45RO', 'CD56', 'CD68', 'CD69', 'CD8', 'COL1A1', 'DC-SIGN', 'Foxp3', 'Granzyme B', 'HLA-DR-DP-DQ', 'HLA-class-1-A-B-C', 'IDO-1', 'Ki67', 'LAG-3', 'MECA-79', 'MelanA', 'PD-1', 'S100A9-Calprotectin', 'SMA', 'SOX10', 'TCF1TCF7', 'TIM-3', 'Tox-Tox2', 'anti-Biotin', 'dsDNA', 'label', 'area', 'eccentricity', 'major_axis_length', 'minor_axis_length', 'perimeter', 'convex_area', 'equivalent_diameter', 'centroid-0', 'centroid-1', 'major_minor_axis_ratio', 'perim_square_over_area', 'major_axis_equiv_diam_ratio', 'convex_hull_resid', 'centroid_dif', 'num_concavities', 'fov', 'pred', 'pred_prob', 'class', 'score', 'spatial', 'Group', 'patient number']\n",
      "shape: (5, 5)\n",
      "┌───────┬────────┬───────────────┬───────┬────────────────┐\n",
      "│ label ┆ fov    ┆ pred          ┆ Group ┆ patient number │\n",
      "│ ---   ┆ ---    ┆ ---           ┆ ---   ┆ ---            │\n",
      "│ f64   ┆ str    ┆ str           ┆ str   ┆ i64            │\n",
      "╞═══════╪════════╪═══════════════╪═══════╪════════════════╡\n",
      "│ 1.0   ┆ FOV48  ┆ blood vessels ┆ G2    ┆ 37             │\n",
      "│ 1.0   ┆ FOV274 ┆ Unidentified  ┆ G3    ┆ 91             │\n",
      "│ 1.0   ┆ FOV150 ┆ B cell        ┆ G2    ┆ 47             │\n",
      "│ 1.0   ┆ FOV46  ┆ CD8 T cell    ┆ G2    ┆ 37             │\n",
      "│ 1.0   ┆ FOV230 ┆ Unidentified  ┆ G1    ┆ 20             │\n",
      "└───────┴────────┴───────────────┴───────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "full_cell_sheet=pl.read_csv(r\"D:\\MIBI-TOFF\\Data_For_Amos\\cleaned_expression_with_both_classification_prob_spatial_30_08_24.csv\")\n",
    "print(full_cell_sheet.columns)\n",
    "cell_frame = full_cell_sheet[['label', 'fov','pred','Group','patient number']]\n",
    "unique_fovs = cell_frame.unique(subset='fov')\n",
    "print(unique_fovs.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "shape: (5, 5)\n",
      "┌───────┬────────┬──────────────┬───────┬────────────────┐\n",
      "│ label ┆ fov    ┆ pred         ┆ Group ┆ patient number │\n",
      "│ ---   ┆ ---    ┆ ---          ┆ ---   ┆ ---            │\n",
      "│ f64   ┆ str    ┆ str          ┆ str   ┆ i64            │\n",
      "╞═══════╪════════╪══════════════╪═══════╪════════════════╡\n",
      "│ 1.0   ┆ FOV274 ┆ Unidentified ┆ G3    ┆ 91             │\n",
      "│ 1.0   ┆ FOV150 ┆ B cell       ┆ G2    ┆ 47             │\n",
      "│ 1.0   ┆ FOV230 ┆ Unidentified ┆ G1    ┆ 20             │\n",
      "│ 1.0   ┆ FOV406 ┆ Unidentified ┆ G4    ┆ 117            │\n",
      "│ 1.0   ┆ FOV76  ┆ Unidentified ┆ G3    ┆ 83             │\n",
      "└───────┴────────┴──────────────┴───────┴────────────────┘\n",
      "\n",
      "Validation Set:\n",
      "shape: (5, 5)\n",
      "┌───────┬────────┬───────────────┬───────┬────────────────┐\n",
      "│ label ┆ fov    ┆ pred          ┆ Group ┆ patient number │\n",
      "│ ---   ┆ ---    ┆ ---           ┆ ---   ┆ ---            │\n",
      "│ f64   ┆ str    ┆ str           ┆ str   ┆ i64            │\n",
      "╞═══════╪════════╪═══════════════╪═══════╪════════════════╡\n",
      "│ 1.0   ┆ FOV48  ┆ blood vessels ┆ G2    ┆ 37             │\n",
      "│ 1.0   ┆ FOV46  ┆ CD8 T cell    ┆ G2    ┆ 37             │\n",
      "│ 1.0   ┆ FOV40  ┆ DC sign Mac   ┆ G2    ┆ 33             │\n",
      "│ 1.0   ┆ FOV54  ┆ Unidentified  ┆ G3    ┆ 74             │\n",
      "│ 1.0   ┆ FOV156 ┆ Neutrophil    ┆ G3    ┆ 86             │\n",
      "└───────┴────────┴───────────────┴───────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "splitter=GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=1995)\n",
    "for train_idx, val_idx in splitter.split(unique_fovs, groups=unique_fovs['patient number']):\n",
    "    train_data = unique_fovs[train_idx]\n",
    "    val_data = unique_fovs[val_idx]\n",
    "    print(\"Training Set:\")\n",
    "    print(train_data.head(5))\n",
    "    print(\"\\nValidation Set:\")\n",
    "    print(val_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir=data_path=r'D:\\MIBI-TOFF\\Data_For_Amos'\n",
    "df=unique_fovs\n",
    "prefix='FOV'\n",
    "fov_col='fov'\n",
    "label_col='Group'\n",
    "image_paths=[]\n",
    "\n",
    "# The loop moves through the predefined file structure of the MIBI dataset being used to identify relevent image samples while filtering out files that we do not want\n",
    "#Theoretically provides 39 expressions but some patients have varying amounts\n",
    "for fov_dir in os.listdir(root_dir):\n",
    "            if fov_dir.startswith(prefix):#replace with Pathlib matching later\n",
    "                fov_path = os.path.join(root_dir, fov_dir)\n",
    "                \n",
    "                if os.path.isdir(fov_path):\n",
    "                    #print(fov_dir)\n",
    "                    # check if the folder name exists in the \"FOV\" column of the DataFrame\n",
    "                    group = df.filter(pl.col(fov_col) == fov_dir)  #why oh why did I decide to decide to use polars instead of pandas for this test?\n",
    "                    if group.height>0:\n",
    "                        # pull the matching data from the \"group\" column\n",
    "                        \n",
    "                        group_data = group[label_col].to_list()[0]  \n",
    "                        #print(group_data,binarized_data)\n",
    "                        tif_path = os.path.join(fov_path, 'TIFs')\n",
    "                        if os.path.exists(tif_path):\n",
    "                            # Load all .tiff files ignoring those with \"segmentation in the name\"\n",
    "                            sublist=[]\n",
    "                            for image_file in os.listdir(tif_path):\n",
    "                                if (image_file.endswith('.tif') or image_file.endswith('.tiff')) and ('segmentation' not in image_file) and not (image_file[0].isdigit()):\n",
    "                                    sublist.append(os.path.join(tif_path, image_file))\n",
    "                            \n",
    "\n",
    "                            sublist.sort()#Should normalize the data assuming the data format is maintained true for this dataset \n",
    "                            #should create a perminant mapping\n",
    "                            image_paths.append(sublist)\n",
    "                        num_sublists = len(sublist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alexa Fluor 488.tif': 177, 'Bax.tif': 177, 'CCR7.tif': 177, 'CD11c.tif': 177, 'CD14.tif': 177, 'CD163.tif': 177, 'CD20.tif': 177, 'CD206.tif': 177, 'CD21.tif': 177, 'CD3.tif': 177, 'CD31.tif': 177, 'CD4.tif': 177, 'CD45.tif': 177, 'CD45RA.tif': 177, 'CD45RO.tif': 177, 'CD56.tif': 177, 'CD68.tif': 177, 'CD69.tif': 177, 'CD8.tif': 177, 'COL1A1.tif': 177, 'DC-SIGN.tif': 177, 'Foxp3.tif': 177, 'Granzyme B.tif': 177, 'HLA-DR-DP-DQ.tif': 177, 'HLA-class-1-A-B-C.tif': 177, 'IDO-1.tif': 177, 'Ki67.tif': 177, 'LAG-3.tif': 177, 'MECA-79.tif': 177, 'MelanA.tif': 177, 'PD-1.tif': 177, 'S100A9-Calprotectin.tif': 177, 'SMA.tif': 177, 'SOX10.tif': 177, 'TCF1TCF7.tif': 177, 'TIM-3.tif': 177, 'Tox-Tox2.tif': 177, 'anti-Biotin.tif': 177, 'dsDNA.tif': 177, 'dsDNA-enhanced.tif': 9, 'dsDNA_cont.tif': 6, 'mask_fov_164.tif': 1, 'CD4_smooth.tif': 3, 'Foxp3_smooth.tif': 1, 'CD14_smooth.tif': 1, 'CD31_smooth.tif': 1, 'CD8_smooth.tif': 2, 'MelanA_enhanced.tif': 1, 'MelanA_smooth.tif': 1, 'S100A9-Calprotectin_smooth.tif': 1, 'dsDNA_smooth.tif': 3, 'dsDNA_enhanced.tif': 2, 'CD20_Smooth.tif': 1, 'CD20_gaussian.tif': 1, 'CD3_gaussian.tif': 1, 'CD3_smooth.tif': 1, 'CD4_gaussian.tif': 1, 'SOX10_gaussian.tif': 1, 'SOX10_smooth.tif': 1, 'CD163_gaussian_2.tif': 1, 'CD163_smooth.tif': 1, 'CD8_gaussian.tif': 1, 'Stack.tif': 1}\n"
     ]
    }
   ],
   "source": [
    "#Find the expressions that are not in every file should be equal to the number of fovs 177 in this sample\n",
    "expressions={}\n",
    "for fov in image_paths:\n",
    "    for path in fov:\n",
    "        filename = os.path.basename(path)\n",
    "        if filename not in expressions:\n",
    "            expressions[filename]=1\n",
    "        else:\n",
    "            expressions[filename]+=1\n",
    "print(expressions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['Alexa Fluor 488.tif', 'Bax.tif', 'CCR7.tif', 'CD11c.tif', 'CD14.tif', 'CD163.tif', 'CD20.tif', 'CD206.tif', 'CD21.tif', 'CD3.tif', 'CD31.tif', 'CD4.tif', 'CD45.tif', 'CD45RA.tif', 'CD45RO.tif', 'CD56.tif', 'CD68.tif', 'CD69.tif', 'CD8.tif', 'COL1A1.tif', 'DC-SIGN.tif', 'Foxp3.tif', 'Granzyme B.tif', 'HLA-DR-DP-DQ.tif', 'HLA-class-1-A-B-C.tif', 'IDO-1.tif', 'Ki67.tif', 'LAG-3.tif', 'MECA-79.tif', 'MelanA.tif', 'PD-1.tif', 'S100A9-Calprotectin.tif', 'SMA.tif', 'SOX10.tif', 'TCF1TCF7.tif', 'TIM-3.tif', 'Tox-Tox2.tif', 'anti-Biotin.tif', 'dsDNA.tif']\n"
     ]
    }
   ],
   "source": [
    "threshold=117\n",
    "consistent_expressions=[key for key, value in expressions.items() if value > threshold]\n",
    "#I have no idea why > is needed to make this work\n",
    "print(len(consistent_expressions))\n",
    "print(consistent_expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths=[]\n",
    "for fov_dir in os.listdir(root_dir):\n",
    "            if fov_dir.startswith(prefix):#replace with Pathlib matching later\n",
    "                fov_path = os.path.join(root_dir, fov_dir)\n",
    "                \n",
    "                if os.path.isdir(fov_path):\n",
    "                    #print(fov_dir)\n",
    "                    # check if the folder name exists in the \"FOV\" column of the DataFrame\n",
    "                    group = df.filter(pl.col(fov_col) == fov_dir)  #why oh why did I decide to decide to use polars instead of pandas for this test?\n",
    "                    if group.height>0:\n",
    "                        # pull the matching data from the \"group\" column\n",
    "                        \n",
    "                        group_data = group[label_col].to_list()[0]  \n",
    "                        #print(group_data,binarized_data)\n",
    "                        tif_path = os.path.join(fov_path, 'TIFs')\n",
    "                        if os.path.exists(tif_path):\n",
    "                            # Load all .tiff files ignoring those with \"segmentation in the name\"\n",
    "                            sublist=[]\n",
    "                            for image_file in os.listdir(tif_path):\n",
    "                                if consistent_expressions:# this is a list of expression names we want to make sure are in the dataset. \n",
    "                                    if image_file in consistent_expressions:\n",
    "                                        sublist.append(os.path.join(tif_path, image_file))\n",
    "\n",
    "                            sublist.sort()#Should normalize the data assuming the data format is maintained true for this dataset \n",
    "                            #should create a perminant mapping\n",
    "                            image_paths.append(sublist)\n",
    "                        num_sublists = len(sublist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV10\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV100\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV102\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV104\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV106\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV108\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV110\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV112\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV114\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV116\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV118\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV12\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV120\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV122\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV124\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV126\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV128\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV130\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV132\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV134\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV136\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV138\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV14\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV140\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV142\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV144\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV146\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV148\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV150\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV152\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV154\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV156\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV158\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV16\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV160\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV162\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV164\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV166\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV168\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV170\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV172\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV174\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV176\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV178\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV18\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV180\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV182\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV184\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV190\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV192\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV194\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV196\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV198\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV2\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV20\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV204\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV206\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV212\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV218\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV22\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV220\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV222\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV224\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV226\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV228\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV230\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV232\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV234\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV236\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV238\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV24\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV240\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV246\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV248\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV250\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV252\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV258\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV26\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV260\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV262\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV268\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV270\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV272\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV274\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV278\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV28\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV280\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV282\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV284\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV286\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV288\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV294\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV296\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV298\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV30\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV300\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV302\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV304\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV306\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV308\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV32\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV322\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV324\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV326\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV332\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV334\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV336\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV338\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV34\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV342\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV344\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV350\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV352\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV354\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV356\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV358\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV36\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV362\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV364\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV366\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV368\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV370\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV372\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV374\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV38\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV380\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV382\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV384\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV390\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV392\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV394\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV4\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV40\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV400\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV402\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV404\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV406\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV408\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV410\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV412\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV418\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV42\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV420\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV422\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV424\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV426\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV428\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV44\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV46\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV48\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV50\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV52\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV54\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV56\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV58\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV6\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV60\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV62\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV64\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV66\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV68\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV70\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV72\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV74\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV76\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV78\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV8\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV80\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV82\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV84\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV86\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV88\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV90\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV92\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV94\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV96\\TIFs\\Alexa Fluor 488.tif 39\n",
      "D:\\MIBI-TOFF\\Data_For_Amos\\FOV98\\TIFs\\Alexa Fluor 488.tif 39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressions_test={}\n",
    "for fov in image_paths:\n",
    "    print(fov[0],len(fov))\n",
    "    for path in fov:\n",
    "        \n",
    "        filename = os.path.basename(path)\n",
    "        if filename not in expressions_test:\n",
    "            expressions_test[filename]=1\n",
    "        else:\n",
    "            expressions_test[filename]+=1\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_3208\\1589236185.py\", line 10, in <module>\n",
      "    train_hdf5 = model_utils.fovs_to_hdf5(root_dir=data_path, df=train_data,hdf5_path=hdf5_path, prefix='FOV', fov_col='fov', label_col='Group', expressions=consistent_expressions)\n",
      "  File \"d:\\MIBI-TOFF\\scripts\\Mibi-Analysis-py\\ImageProcessing\\model_utils.py\", line 148, in fovs_to_hdf5\n",
      "    _gen_patches_hdf5(image_paths,labels,hdf5_path=hdf5_path,patch_size_x=patch_size_x,patch_size_y=patch_size_y)\n",
      "  File \"d:\\MIBI-TOFF\\scripts\\Mibi-Analysis-py\\ImageProcessing\\model_utils.py\", line 193, in _gen_patches_hdf5\n",
      "  File \"h5py\\\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\h5py\\_hl\\dataset.py\", line 999, in __setitem__\n",
      "    self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import model_utils\n",
    "import importlib\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "\n",
    "import os\n",
    "hdf5_path = os.getcwd()  # Set hdf5_path to the current working directory\n",
    "hdf5_path = os.path.join(hdf5_path, 'training.h5') \n",
    "\n",
    "train_hdf5 = model_utils.fovs_to_hdf5(root_dir=data_path, df=train_data,hdf5_path=hdf5_path, prefix='FOV', fov_col='fov', label_col='Group', expressions=consistent_expressions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model_utils\n",
    "from mibi_dataset import MibiDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "data_path=r'D:\\MIBI-TOFF\\Data_For_Amos'\n",
    "train_dataset=MibiDataset(root_dir=data_path,df=train_data,prefix='FOV',fov_col='fov',label_col='Group', transform=None,expressions=consistent_expressions)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=1,shuffle=True)\n",
    "\n",
    "val_dataset=MibiDataset(root_dir=data_path,df=val_data,prefix='FOV',fov_col='fov',label_col='Group', transform=None,expressions=consistent_expressions)\n",
    "val_loader=DataLoader(dataset=train_dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV64\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.390625|| last output:tensor([[  9.8570, -10.4590]], grad_fn=<AddmmBackward0>)|| running_loss:0.4889759953657631\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV308\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.390625|| last output:tensor([[  9.5316, -10.6180]], grad_fn=<AddmmBackward0>)|| running_loss:0.4889759953657631\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV344\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.3875732421875|| last output:tensor([[-11.3420,   9.8339]], grad_fn=<AddmmBackward0>)|| running_loss:42.733306981618966\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV342\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4115513392857143|| last output:tensor([[-11.1308,  10.0810]], grad_fn=<AddmmBackward0>)|| running_loss:42.733306981618966\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV364\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4326171875|| last output:tensor([[ 17.8772, -18.0405]], grad_fn=<AddmmBackward0>)|| running_loss:104.1118043371929\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV228\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4191080729166667|| last output:tensor([[-23.3419,  24.2061]], grad_fn=<AddmmBackward0>)|| running_loss:301.37766758458235\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV178\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4361736240671642|| last output:tensor([[-23.3411,  24.3575]], grad_fn=<AddmmBackward0>)|| running_loss:301.37766758458235\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV222\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.42739316641566266|| last output:tensor([[-23.7508,  24.1660]], grad_fn=<AddmmBackward0>)|| running_loss:301.37766758458235\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV284\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4184915561868687|| last output:tensor([[ 23.0730, -21.5839]], grad_fn=<AddmmBackward0>)|| running_loss:637.1490251145898\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV8\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41206691576086957|| last output:tensor([[-20.5933,  21.6040]], grad_fn=<AddmmBackward0>)|| running_loss:962.7705757840887\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV262\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.407025286259542|| last output:tensor([[ 17.4571, -16.7801]], grad_fn=<AddmmBackward0>)|| running_loss:1298.3565464958124\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV418\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41577888257575757|| last output:tensor([[ 16.7562, -16.7102]], grad_fn=<AddmmBackward0>)|| running_loss:1298.3565464958124\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV234\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4130595439189189|| last output:tensor([[ 17.6658, -17.0049]], grad_fn=<AddmmBackward0>)|| running_loss:1298.3565464958124\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV338\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4197907927852349|| last output:tensor([[-11.2494,  11.1964]], grad_fn=<AddmmBackward0>)|| running_loss:1446.0588266741856\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV226\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4169625946969697|| last output:tensor([[-11.5351,  11.2115]], grad_fn=<AddmmBackward0>)|| running_loss:1446.0588266741856\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV294\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.413420450621547|| last output:tensor([[ 15.8562, -16.3148]], grad_fn=<AddmmBackward0>)|| running_loss:1569.4848061718621\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV230\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40995796319796957|| last output:tensor([[-12.9206,  12.4784]], grad_fn=<AddmmBackward0>)|| running_loss:1810.6822878223525\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV22\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40724490170187794|| last output:tensor([[ 14.3558, -13.9051]], grad_fn=<AddmmBackward0>)|| running_loss:1982.6977769805594\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV218\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40491095796943233|| last output:tensor([[-14.2467,  14.0168]], grad_fn=<AddmmBackward0>)|| running_loss:2179.462578075081\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV82\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40994395380434784|| last output:tensor([[-14.0298,  14.0267]], grad_fn=<AddmmBackward0>)|| running_loss:2179.462578075081\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV142\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.407397262449187|| last output:tensor([[ 4.8061, -4.7116]], grad_fn=<AddmmBackward0>)|| running_loss:2383.3108106776326\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV86\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40581390147900764|| last output:tensor([[-8.4757,  9.3602]], grad_fn=<AddmmBackward0>)|| running_loss:2416.4021727446734\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV304\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4040615164118705|| last output:tensor([[ 6.2143, -5.7380]], grad_fn=<AddmmBackward0>)|| running_loss:2518.279199825259\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV270\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4033302774234694|| last output:tensor([[ 6.1568, -5.9321]], grad_fn=<AddmmBackward0>)|| running_loss:2518.2806669295924\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV110\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4065975900423729|| last output:tensor([[-10.4197,  10.3127]], grad_fn=<AddmmBackward0>)|| running_loss:2578.644172631508\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV410\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4105026657516892|| last output:tensor([[-10.5337,  10.4801]], grad_fn=<AddmmBackward0>)|| running_loss:2578.644172631508\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV420\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41355942234848486|| last output:tensor([[ 4.8754, -4.9071]], grad_fn=<AddmmBackward0>)|| running_loss:2700.0294980608505\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV146\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4123870557108626|| last output:tensor([[ 5.1257, -5.0726]], grad_fn=<AddmmBackward0>)|| running_loss:2700.045533564562\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV100\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41080927051671734|| last output:tensor([[-9.2966,  9.2090]], grad_fn=<AddmmBackward0>)|| running_loss:2743.400505334567\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV148\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40909476902173914|| last output:tensor([[ 3.6976, -3.3840]], grad_fn=<AddmmBackward0>)|| running_loss:2857.563195773421\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV204\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4076675034626039|| last output:tensor([[-6.5431,  6.7176]], grad_fn=<AddmmBackward0>)|| running_loss:2896.5357463116334\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV394\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.410857648480663|| last output:tensor([[-6.1361,  6.3923]], grad_fn=<AddmmBackward0>)|| running_loss:2896.5359549275236\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV354\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41000124007936506|| last output:tensor([[-6.1717,  6.3828]], grad_fn=<AddmmBackward0>)|| running_loss:2896.5367338397755\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV116\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40921438769035534|| last output:tensor([[-5.9463,  6.3350]], grad_fn=<AddmmBackward0>)|| running_loss:2896.5375222887246\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV224\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4084889481707317|| last output:tensor([[-6.5175,  6.6700]], grad_fn=<AddmmBackward0>)|| running_loss:2896.5383110953117\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV68\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.407359521713615|| last output:tensor([[ 4.4050, -4.2821]], grad_fn=<AddmmBackward0>)|| running_loss:2961.7392475735105\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV154\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4067537471719457|| last output:tensor([[ 4.7205, -4.5600]], grad_fn=<AddmmBackward0>)|| running_loss:2961.790977572309\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV66\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.406190297489083|| last output:tensor([[ 4.8692, -4.9188]], grad_fn=<AddmmBackward0>)|| running_loss:2961.8200191571523\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV296\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4056648866033755|| last output:tensor([[ 5.0199, -5.0997]], grad_fn=<AddmmBackward0>)|| running_loss:2961.8393986954325\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV232\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40517378826530615|| last output:tensor([[ 5.1861, -5.1423]], grad_fn=<AddmmBackward0>)|| running_loss:2961.8537170031213\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV392\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4075308681262729|| last output:tensor([[ 4.9835, -4.9126]], grad_fn=<AddmmBackward0>)|| running_loss:2961.8569491234703\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV260\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4069973496055227|| last output:tensor([[ 5.4914, -5.6049]], grad_fn=<AddmmBackward0>)|| running_loss:2961.867577588513\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV88\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40626307062619504|| last output:tensor([[-12.6986,  12.5046]], grad_fn=<AddmmBackward0>)|| running_loss:2991.822323322036\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV402\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40846962965171757|| last output:tensor([[-12.6202,  12.4069]], grad_fn=<AddmmBackward0>)|| running_loss:2991.822323322036\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV274\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4075792100694444|| last output:tensor([[ 4.0590, -4.2675]], grad_fn=<AddmmBackward0>)|| running_loss:3107.7688856210243\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV426\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4097139989602588|| last output:tensor([[ 4.3509, -4.4626]], grad_fn=<AddmmBackward0>)|| running_loss:3107.781089553815\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV80\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40894650471274685|| last output:tensor([[-5.5136,  5.3589]], grad_fn=<AddmmBackward0>)|| running_loss:3134.5921364652027\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV172\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40843490946771377|| last output:tensor([[-5.6400,  5.7219]], grad_fn=<AddmmBackward0>)|| running_loss:3134.599490936647\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV6\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40795110887096775|| last output:tensor([[-6.1541,  6.2909]], grad_fn=<AddmmBackward0>)|| running_loss:3134.6009456367906\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV400\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4099079713983051|| last output:tensor([[-5.9498,  5.8730]], grad_fn=<AddmmBackward0>)|| running_loss:3134.6013993406436\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV288\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4091974138820132|| last output:tensor([[ 5.0822, -5.1531]], grad_fn=<AddmmBackward0>)|| running_loss:3176.860790408086\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV104\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41077565125617793|| last output:tensor([[-3.9184,  4.1945]], grad_fn=<AddmmBackward0>)|| running_loss:3224.1485982354066\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV422\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.41006219903691815|| last output:tensor([[ 7.2641, -7.0498]], grad_fn=<AddmmBackward0>)|| running_loss:3250.789461267798\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV84\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40930806191314556|| last output:tensor([[-5.5072,  5.1651]], grad_fn=<AddmmBackward0>)|| running_loss:3301.568394607971\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV134\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4088516817748092|| last output:tensor([[-5.4266,  5.2303]], grad_fn=<AddmmBackward0>)|| running_loss:3301.5752299652445\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV10\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40841706641207154|| last output:tensor([[-5.2167,  5.1566]], grad_fn=<AddmmBackward0>)|| running_loss:3301.5814716789178\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV124\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4080026951419214|| last output:tensor([[-5.2940,  4.9258]], grad_fn=<AddmmBackward0>)|| running_loss:3301.5874660389286\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV198\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40760718572190613|| last output:tensor([[-5.4380,  5.2030]], grad_fn=<AddmmBackward0>)|| running_loss:3301.593163932556\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV150\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40699158988178025|| last output:tensor([[ 3.9604, -3.9695]], grad_fn=<AddmmBackward0>)|| running_loss:3347.9187817733896\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV286\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4066353103741497|| last output:tensor([[ 4.0845, -4.2445]], grad_fn=<AddmmBackward0>)|| running_loss:3348.0085013541525\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV196\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40603414197736354|| last output:tensor([[-4.8183,  5.2564]], grad_fn=<AddmmBackward0>)|| running_loss:3385.787535640508\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV278\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4055535466916558|| last output:tensor([[ 3.9915, -4.2366]], grad_fn=<AddmmBackward0>)|| running_loss:3420.1858855300766\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV12\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.405061412436143|| last output:tensor([[-4.4653,  4.2717]], grad_fn=<AddmmBackward0>)|| running_loss:3453.0721174720334\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV144\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40465009973404253|| last output:tensor([[ 3.8706, -3.7077]], grad_fn=<AddmmBackward0>)|| running_loss:3477.680196269643\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV106\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4058837890625|| last output:tensor([[-3.1381,  3.3204]], grad_fn=<AddmmBackward0>)|| running_loss:3509.909031279962\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV136\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40558459712009803|| last output:tensor([[-4.0616,  4.2200]], grad_fn=<AddmmBackward0>)|| running_loss:3510.0641886596372\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV180\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40529691256009615|| last output:tensor([[-4.2696,  4.3180]], grad_fn=<AddmmBackward0>)|| running_loss:3510.1235899232365\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV366\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4048473430129717|| last output:tensor([[ 3.9038, -4.0805]], grad_fn=<AddmmBackward0>)|| running_loss:3545.8735502165605\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV126\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4044426812065972|| last output:tensor([[-4.2694,  4.3132]], grad_fn=<AddmmBackward0>)|| running_loss:3574.186171849268\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV114\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40419145063920453|| last output:tensor([[-4.3282,  4.2004]], grad_fn=<AddmmBackward0>)|| running_loss:3574.2408698058666\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV324\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4039491925920759|| last output:tensor([[-4.4031,  4.3631]], grad_fn=<AddmmBackward0>)|| running_loss:3574.2739975647223\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV302\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40355481599506576|| last output:tensor([[ 3.8614, -3.6823]], grad_fn=<AddmmBackward0>)|| running_loss:3607.4612937074367\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV176\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4046370139649507|| last output:tensor([[-3.4413,  3.3651]], grad_fn=<AddmmBackward0>)|| running_loss:3640.523066829434\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV248\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4042642878767492|| last output:tensor([[ 4.0476, -4.0220]], grad_fn=<AddmmBackward0>)|| running_loss:3662.9555257689885\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV50\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40403335813492064|| last output:tensor([[ 4.2566, -4.2127]], grad_fn=<AddmmBackward0>)|| running_loss:3663.020758726236\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV300\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4052579528937632|| last output:tensor([[ 4.5593, -4.5886]], grad_fn=<AddmmBackward0>)|| running_loss:3663.0315359365363\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV382\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4063252788410771|| last output:tensor([[-2.8017,  2.9064]], grad_fn=<AddmmBackward0>)|| running_loss:3698.544073660409\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV36\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4060644227024922|| last output:tensor([[-3.6232,  3.7933]], grad_fn=<AddmmBackward0>)|| running_loss:3698.807606770543\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV250\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40563752872829417|| last output:tensor([[ 3.9779, -3.8850]], grad_fn=<AddmmBackward0>)|| running_loss:3733.1645494369463\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV252\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40539612123115576|| last output:tensor([[ 4.0530, -4.1065]], grad_fn=<AddmmBackward0>)|| running_loss:3733.250345566996\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV44\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4051623547230465|| last output:tensor([[ 4.2130, -4.0632]], grad_fn=<AddmmBackward0>)|| running_loss:3733.3076805713085\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV118\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4047456943768257|| last output:tensor([[-4.1271,  3.7850]], grad_fn=<AddmmBackward0>)|| running_loss:3778.9664463042595\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV76\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40431840993528284|| last output:tensor([[ 4.7376, -4.7902]], grad_fn=<AddmmBackward0>)|| running_loss:3818.074548021725\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV92\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4038579290604344|| last output:tensor([[-3.3672,  3.2962]], grad_fn=<AddmmBackward0>)|| running_loss:3872.2938039595706\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV220\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4036609738372093|| last output:tensor([[-3.8361,  3.7828]], grad_fn=<AddmmBackward0>)|| running_loss:3872.512854731273\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV280\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40324601856095327|| last output:tensor([[ 3.4534, -3.4559]], grad_fn=<AddmmBackward0>)|| running_loss:3922.1185708909566\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV390\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40430760645604397|| last output:tensor([[ 3.4261, -3.4964]], grad_fn=<AddmmBackward0>)|| running_loss:3922.172050288102\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV408\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4050992108874657|| last output:tensor([[-2.4844,  2.5891]], grad_fn=<AddmmBackward0>)|| running_loss:3973.0213313514055\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV174\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40489038548241657|| last output:tensor([[-3.2339,  3.2868]], grad_fn=<AddmmBackward0>)|| running_loss:3973.6200747548523\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV298\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40566934121621623|| last output:tensor([[ 2.7852, -2.8253]], grad_fn=<AddmmBackward0>)|| running_loss:4023.091556634327\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV190\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4064249198357336|| last output:tensor([[-2.3666,  2.2513]], grad_fn=<AddmmBackward0>)|| running_loss:4066.5013850271157\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV380\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40746455569919066|| last output:tensor([[-2.6491,  2.6182]], grad_fn=<AddmmBackward0>)|| running_loss:4066.9669585139877\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV72\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.4069010416666667|| last output:tensor([[ 3.0110, -3.0273]], grad_fn=<AddmmBackward0>)|| running_loss:4116.469360892932\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV102\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40757860938883966|| last output:tensor([[-1.9585,  1.9499]], grad_fn=<AddmmBackward0>)|| running_loss:4175.473225782896\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV62\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40702186817685587|| last output:tensor([[ 2.9297, -2.9477]], grad_fn=<AddmmBackward0>)|| running_loss:4218.29898971812\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV26\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40679589927863913|| last output:tensor([[ 3.3511, -3.3067]], grad_fn=<AddmmBackward0>)|| running_loss:4218.740429773092\n",
      "tensor([1])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV96\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40620270682880205|| last output:tensor([[-2.9562,  3.0339]], grad_fn=<AddmmBackward0>)|| running_loss:4287.8739550090195\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV368\\\\TIFs\\\\Alexa Fluor 488.tif',)\n",
      "Correct:0.40566635451592625|| last output:tensor([[ 3.0284, -2.8089]], grad_fn=<AddmmBackward0>)|| running_loss:4348.128981255906\n",
      "tensor([0])\n",
      "('D:\\\\MIBI-TOFF\\\\Data_For_Amos\\\\FOV24\\\\TIFs\\\\Alexa Fluor 488.tif',)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)  \u001b[38;5;66;03m# Define the optimizer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Set device to GPU (0)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\scripts\\Mibi-Analysis-py\\ImageProcessing\\model_utils.py:29\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, device, epochs, check_val_freq)\u001b[0m\n\u001b[0;32m     27\u001b[0m patch \u001b[38;5;241m=\u001b[39m patches\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 29\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\scripts\\Mibi-Analysis-py\\ImageProcessing\\mibi_vit.py:33\u001b[0m, in \u001b[0;36mViTBinaryClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Transformer blocks\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size * patches_per_image, num_patches + 1, embed_dim)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Use the [CLS] token for classification\u001b[39;00m\n\u001b[0;32m     36\u001b[0m cls_output \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (batch_size * patches_per_image, embed_dim)\u001b[39;00m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:416\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    413\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 416\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    419\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:750\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[1;32m--> 750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:765\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 765\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\nn\\functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import model_utils\n",
    "from mibi_vit import ViTBinaryClassifier\n",
    "model = ViTBinaryClassifier(img_size_x=128, img_size_y=128, in_channels=39, num_classes=2, patch_size_x=16, patch_size_y=16, embed_dim=768, num_heads=4, depth=6, mlp_dim=3072)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define the classification criterion\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Define the optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Set device to GPU (0)\n",
    "\n",
    "model_utils.train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mibivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
