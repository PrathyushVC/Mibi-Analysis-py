{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook is designed to facilitate the training and evaluation of a Vision Transformer (ViT) model for binary classification tasks using MIBI (Multiplexed Imaging) datasets.\n",
    " \n",
    "The main functions of this notebook include:\n",
    " \n",
    "1. **CUDA Availability Check**: The notebook checks if a CUDA-enabled GPU is available for training, which can significantly speed up the training process.\n",
    "\n",
    "2. **Data Loading**: It utilizes the `MibiDataset` class to load training, validation, and testing datasets from specified HDF5 files. Data loaders are created for each dataset to facilitate batch processing during training.\n",
    " \n",
    "3. **Model Training**: The notebook is set up to train a ViT model using the `train_model` function from the `model_utils` module. This function handles the training loop, loss calculation, and optimization.\n",
    "\n",
    "4. **Model Evaluation**: After training, the model can be evaluated on the validation and test datasets to assess its performance using various metrics.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Number of GPUs available: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "PyTorch built with CUDA Version: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os,sys\n",
    "import polars as pl\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"PyTorch built with CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path=os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path,'NN_Framework')))\n",
    "from NN_Framework import utils\n",
    "from NN_Framework.mibi_dataset import MibiDataset\n",
    "from NN_Framework.models import GraphConvClassifier\n",
    "from NN_Framework.mibi_data_prep_graph import remapping, create_graph\n",
    "\n",
    "from NN_Framework.multichannel_transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_types = ['MelanA', 'Ki67', 'SOX10', 'COL1A1', 'SMA', \n",
    "                   'CD206', 'CD8', 'CD4', 'CD45', 'CD3', 'CD20', 'CD11c']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pl.read_csv(r\"D:\\MIBI-TOFF\\Data_For_Amos\\cleaned_expression_with_both_classification_prob_spatial_30_08_24.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(r'D:\\MIBI-TOFF\\Mibi-Analysis-py\\data_split_20241102_173851.pkl', 'rb') as pickle_file:\n",
    "    data_loaded = pickle.load(pickle_file)\n",
    "\n",
    "train_data = pl.DataFrame(data_loaded['train_data'])\n",
    "val_data = pl.DataFrame(data_loaded['val_data'])\n",
    "test_data = pl.DataFrame(data_loaded['test_data'])\n",
    "\n",
    "# Filter full_df to get overlapping FOVs for each of train, val, and test datasets\n",
    "train_fovs = full_df.filter(pl.col('fov').is_in(train_data['fov']))\n",
    "val_fovs = full_df.filter(pl.col('fov').is_in(val_data['fov']))\n",
    "test_fovs = full_df.filter(pl.col('fov').is_in(test_data['fov']))\n",
    "\n",
    "train_fovs = train_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))#Remove confounding cells\n",
    "val_fovs = val_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))\n",
    "test_fovs = test_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))\n",
    "\n",
    "train_fovs=remapping(df=train_fovs, column_name='pred')#remap larger cell name list to smaller one \n",
    "val_fovs=remapping(df=val_fovs, column_name='pred')#remap larger cell name list to smaller one \n",
    "test_fovs=remapping(df=test_fovs, column_name='pred')#remap larger cell name list to smaller one \n",
    "\n",
    "\n",
    "train_graphs = create_graph(train_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "val_graphs = create_graph(val_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "test_graphs = create_graph(test_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "\n",
    "torch.save(train_graphs, r\"D:\\MIBI-TOFF\\Scratch\\train_full_r25_graphs.pt\")\n",
    "torch.save(val_graphs, r\"D:\\MIBI-TOFF\\Scratch\\val_full_r25_graphs.pt\")\n",
    "torch.save(test_graphs, r\"D:\\MIBI-TOFF\\Scratch\\test_full_r25_graphs.pt\")\n",
    "\n",
    "print(f\"Saved {len(train_graphs)} train graphs.\")\n",
    "print(f\"Saved {len(val_graphs)} val graphs.\")\n",
    "print(f\"Saved {len(val_graphs)} test graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_30660\\2729449956.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_graphs =torch.load( r\"D:\\MIBI-TOFF\\Scratch\\train_full_r25_graphs.pt\")\n",
      "C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_30660\\2729449956.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\val_full_r25_graphs.pt\")\n",
      "C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_30660\\2729449956.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\test_full_r25_graphs.pt\")\n"
     ]
    }
   ],
   "source": [
    "train_graphs =torch.load( r\"D:\\MIBI-TOFF\\Scratch\\train_full_r25_graphs.pt\")\n",
    "val_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\val_full_r25_graphs.pt\")\n",
    "test_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\test_full_r25_graphs.pt\")\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=5, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=5, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN\n",
      "False cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model_name='full_GCN_12_channel_'\n",
    "\n",
    "# Model selection based on name\n",
    "if any(x in model_name.lower() for x in ['gcn']):\n",
    "    print('GCN')\n",
    "    model = GraphConvClassifier(input_dim=len(expression_types)+4, hidden_dim=128, num_classes=2)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Model type not recognized in model name: {model_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define the classification criterion\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=1e-5)  # Define the optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Set device to GPU (0)\n",
    "model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(torch.cuda.is_available(),device)\n",
    "print(next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending MLFlow if an issue causes it to not close correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Block\n",
    "params_block={'location':r'D:\\MIBI-TOFF\\Scratch\\DL_Results',\n",
    "'epochs':200,\n",
    "'patience':200,\n",
    "'delta':0.00000001,\n",
    "'check_val_freq':5,\n",
    "'num_classes':2,\n",
    "'model_name':model_name,\n",
    "'log_with_mlflow':True,\n",
    "'mlflow_uri':\"http://127.0.0.1:5000\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started MLflow run with ID: 2b9793476c264fef80d8f4a6495542bb\n",
      "After patch_embed: torch.Size([5, 1024, 96])\n",
      "Layer 0: BasicSwinLayer(\n",
      "  (blocks): ModuleList(\n",
      "    (0-1): 2 x SwinBlock(\n",
      "      (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): WindowAttention(\n",
      "        (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "        (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (downsample): PatchMerging(\n",
      "    (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "An error occurred during training: shape '[5, 4, 4, 96]' is invalid for input of size 491520\n",
      "Closing logging\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [], [], [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_train.train_model(model, train_loader, val_loader, criterion, optimizer, device, location=params_block['location'], \n",
    "    epochs=params_block['epochs'], patience=params_block['patience'], delta=params_block['delta'], check_val_freq=params_block['check_val_freq'],\n",
    "    num_classes=params_block['num_classes'], model_name=params_block['model_name'], log_with_mlflow=params_block['log_with_mlflow'], mlflow_uri=params_block['mlflow_uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chirr\\AppData\\Local\\Temp\\ipykernel_14228\\3852113537.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(params_block['location'], f\"{params_block['model_name']}best_model.pth\")))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\MIBI-TOFF\\\\Scratch\\\\DL_Results\\\\512_swin_12_channel_best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams_block\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m avg_test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model_utils\u001b[38;5;241m.\u001b[39meval_model(model, test_loader, criterion, device, params_block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m], epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\MIBI-TOFF\\mibivenv\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\MIBI-TOFF\\\\Scratch\\\\DL_Results\\\\512_swin_12_channel_best_model.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(os.path.join(params_block['location'], f\"{params_block['model_name']}best_model.pth\")))\n",
    "\n",
    "avg_test_loss, test_metrics = model_utils.eval_model(model, test_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the eval_model function\n",
    "avg_val_loss, val_metrics = model_utils.eval_model(model, val_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "# Print all the metrics\n",
    "print(f\"Test Loss: {avg_val_loss:.4f}\")\n",
    "for metric_val_name, metric_val_value in val_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loader)\n",
    "print(val_loader)\n",
    "# Compare the contents of the two loaders\n",
    "test_data = [data for data, _ in test_loader]\n",
    "val_data = [data for data, _ in val_loader]\n",
    "\n",
    "# Check if the lengths of the datasets are the same\n",
    "if len(test_data) == len(val_data):\n",
    "    print(\"The test and validation loaders have the same number of batches.\")\n",
    "else:\n",
    "    print(f\"The test loader has {len(test_data)} batches, while the validation loader has {len(val_data)} batches.\")\n",
    "\n",
    "# Compare the contents of the first batch in both loaders\n",
    "if test_data and val_data:\n",
    "    print(\"Comparing the first batch of test and validation loaders:\")\n",
    "    print(\"Test batch:\", test_data[0])\n",
    "    print(\"Validation batch:\", val_data[0])\n",
    "else:\n",
    "    print(\"One of the loaders is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mibivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
