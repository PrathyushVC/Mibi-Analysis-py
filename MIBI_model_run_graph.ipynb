{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook is designed to facilitate the training and evaluation of a Vision Transformer (ViT) model for binary classification tasks using MIBI (Multiplexed Imaging) datasets.\n",
    " \n",
    "The main functions of this notebook include:\n",
    " \n",
    "1. **CUDA Availability Check**: The notebook checks if a CUDA-enabled GPU is available for training, which can significantly speed up the training process.\n",
    "\n",
    "2. **Data Loading**: It utilizes the `MibiDataset` class to load training, validation, and testing datasets from specified HDF5 files. Data loaders are created for each dataset to facilitate batch processing during training.\n",
    " \n",
    "3. **Model Training**: The notebook is set up to train a ViT model using the `train_model` function from the `model_utils` module. This function handles the training loop, loss calculation, and optimization.\n",
    "\n",
    "4. **Model Evaluation**: After training, the model can be evaluated on the validation and test datasets to assess its performance using various metrics.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os,sys\n",
    "import polars as pl\n",
    "import mlflow\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"PyTorch built with CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path=os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path,'NN_Framework')))\n",
    "from NN_Framework import utils, graph_model_train\n",
    "from NN_Framework.mibi_dataset import MibiDataset\n",
    "from NN_Framework.models import GraphConvClassifier\n",
    "from NN_Framework.mibi_data_prep_graph import remapping, create_graph\n",
    "\n",
    "from NN_Framework.multichannel_transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_types = ['MelanA', 'Ki67', 'SOX10', 'COL1A1', 'SMA', \n",
    "                   'CD206', 'CD8', 'CD4', 'CD45', 'CD3', 'CD20', 'CD11c']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pl.read_csv(r\"D:\\MIBI-TOFF\\Data_For_Amos\\cleaned_expression_with_both_classification_prob_spatial_30_08_24.csv\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(r'D:\\MIBI-TOFF\\Mibi-Analysis-py\\data_split_20241102_173851.pkl', 'rb') as pickle_file:\n",
    "    data_loaded = pickle.load(pickle_file)\n",
    "\n",
    "train_data = pl.DataFrame(data_loaded['train_data'])\n",
    "val_data = pl.DataFrame(data_loaded['val_data'])\n",
    "test_data = pl.DataFrame(data_loaded['test_data'])\n",
    "\n",
    "# Filter full_df to get overlapping FOVs for each of train, val, and test datasets\n",
    "train_fovs = full_df.filter(pl.col('fov').is_in(train_data['fov']))\n",
    "val_fovs = full_df.filter(pl.col('fov').is_in(val_data['fov']))\n",
    "test_fovs = full_df.filter(pl.col('fov').is_in(test_data['fov']))\n",
    "\n",
    "del train_data, val_data, test_data\n",
    "\n",
    "train_fovs = train_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))#Remove confounding cells\n",
    "val_fovs = val_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))\n",
    "test_fovs = test_fovs.filter(~pl.col('pred').is_in(['Unidentified', 'Immune']))\n",
    "\n",
    "train_fovs=remapping(df=train_fovs, column_name='pred')#remap larger cell name list to smaller one \n",
    "train_graphs = create_graph(train_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "del train_fovs\n",
    "\n",
    "\n",
    "val_fovs=remapping(df=val_fovs, column_name='pred')#remap larger cell name list to smaller one\n",
    "val_graphs = create_graph(val_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "del val_fovs\n",
    "\n",
    "test_fovs=remapping(df=test_fovs, column_name='pred')#remap larger cell name list to smaller one \n",
    "test_graphs = create_graph(test_fovs, expression_types, cell_type_col='remapped', radius=25)\n",
    "del test_fovs\n",
    "\n",
    "torch.save(train_graphs, r\"D:\\MIBI-TOFF\\Scratch\\train_full_r25_graphs.pt\")\n",
    "torch.save(val_graphs, r\"D:\\MIBI-TOFF\\Scratch\\val_full_r25_graphs.pt\")\n",
    "torch.save(test_graphs, r\"D:\\MIBI-TOFF\\Scratch\\test_full_r25_graphs.pt\")\n",
    "\n",
    "print(f\"Saved {len(train_graphs)} train graphs.\")\n",
    "print(f\"Saved {len(val_graphs)} val graphs.\")\n",
    "print(f\"Saved {len(val_graphs)} test graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs =torch.load( r\"D:\\MIBI-TOFF\\Scratch\\train_full_r25_graphs.pt\")\n",
    "val_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\val_full_r25_graphs.pt\")\n",
    "test_graphs = torch.load( r\"D:\\MIBI-TOFF\\Scratch\\test_full_r25_graphs.pt\")\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='full_GCN_12_channel_'\n",
    "\n",
    "# Model selection based on name\n",
    "if any(x in model_name.lower() for x in ['gcn']):\n",
    "    print('GCN')\n",
    "    model = GraphConvClassifier(input_dim=len(expression_types)+4, hidden_dim=128, num_classes=2)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Model type not recognized in model name: {model_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define the classification criterion\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=1e-5)  # Define the optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Set device to GPU (0)\n",
    "model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(torch.cuda.is_available(),device)\n",
    "print(next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending MLFlow if an issue causes it to not close correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Block\n",
    "params_block={'location':r'D:\\MIBI-TOFF\\Scratch\\DL_Results',\n",
    "'epochs':200,\n",
    "'patience':200,\n",
    "'delta':0.00000001,\n",
    "'check_val_freq':5,\n",
    "'num_classes':2,\n",
    "'model_name':model_name,\n",
    "'log_with_mlflow':True,\n",
    "'mlflow_uri':\"http://127.0.0.1:5000\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Feature Dims Training\n",
    "for i, data in enumerate(train_loader.dataset):\n",
    "    print(f\"Graph {i}:\")\n",
    "    print(f\"  Node feature shape: {data.x.shape}\")\n",
    "    print(f\"  Edge index shape: {data.edge_index.shape}\")\n",
    "    if data.edge_attr is not None:\n",
    "        print(f\"  Edge attribute shape: {data.edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Feature Dims Training\n",
    "for i, data in enumerate(val_loader.dataset):\n",
    "    print(f\"Graph {i}:\")\n",
    "    print(f\"  Node feature shape: {data.x.shape}\")\n",
    "    print(f\"  Edge index shape: {data.edge_index.shape}\")\n",
    "    if data.edge_attr is not None:\n",
    "        print(f\"  Edge attribute shape: {data.edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(\"Batch node features shape:\", batch.x.shape)\n",
    "print(\"Batch edge index shape:\", batch.edge_index.shape)\n",
    "if batch.edge_attr is not None:\n",
    "    print(\"Batch edge attributes shape:\", batch.edge_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_model_train.train_model(model, train_loader, val_loader, criterion, optimizer, device, location=params_block['location'], \n",
    "    epochs=params_block['epochs'], patience=params_block['patience'], delta=params_block['delta'], check_val_freq=params_block['check_val_freq'],\n",
    "    num_classes=params_block['num_classes'], model_name=params_block['model_name'], log_with_mlflow=params_block['log_with_mlflow'], mlflow_uri=params_block['mlflow_uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(os.path.join(params_block['location'], f\"{params_block['model_name']}best_model.pth\")))\n",
    "\n",
    "avg_test_loss, test_metrics = model_utils.eval_model(model, test_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the eval_model function\n",
    "avg_val_loss, val_metrics = model_utils.eval_model(model, val_loader, criterion, device, params_block['num_classes'], epoch=0)\n",
    "\n",
    "# Print all the metrics\n",
    "print(f\"Test Loss: {avg_val_loss:.4f}\")\n",
    "for metric_val_name, metric_val_value in val_metrics.items():\n",
    "    print(metric_name,metric_value)\n",
    "    #print(f\"{metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loader)\n",
    "print(val_loader)\n",
    "# Compare the contents of the two loaders\n",
    "test_data = [data for data, _ in test_loader]\n",
    "val_data = [data for data, _ in val_loader]\n",
    "\n",
    "# Check if the lengths of the datasets are the same\n",
    "if len(test_data) == len(val_data):\n",
    "    print(\"The test and validation loaders have the same number of batches.\")\n",
    "else:\n",
    "    print(f\"The test loader has {len(test_data)} batches, while the validation loader has {len(val_data)} batches.\")\n",
    "\n",
    "# Compare the contents of the first batch in both loaders\n",
    "if test_data and val_data:\n",
    "    print(\"Comparing the first batch of test and validation loaders:\")\n",
    "    print(\"Test batch:\", test_data[0])\n",
    "    print(\"Validation batch:\", val_data[0])\n",
    "else:\n",
    "    print(\"One of the loaders is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mibivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
